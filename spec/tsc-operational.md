# TSC Operational v2.2.2 - Complete Final Version

```markdown
# Triadic Self-Coherence (TSC) — Operational

**Version:** 2.2.2 (Braided Algebra & Policy Integration)
**Status:** Normative (policy and procedure)
**Dependency:** This document depends on **TSC Core v2.2.2** and **C≡ v2.2.2**.

---

## 0 · Purpose and Position in the Stack

**Purpose.** The Operational layer is the **policy and procedure** that turns the Core's measurement calculus into a **repeatable verification process** with **verdicts**, **witnesses**, and **governance**. It answers:
- *What to run* (protocol),
- *With which parameters* (policy),
- *When to accept or reject* (verdict rules),
- *How to remain stable and reproducible over time* (witnesses, logging, controller).

**What it adds (and only this):**
1. A **verification protocol** over the Core's constructs.
2. **Parameter registry** and recommended **default budgets**.
3. **Witnesses** guarding against degenerate or ill-posed comparisons.
4. A minimal **controller** that adapts solver ensembles and budgets.
5. **Reproducibility and provenance** requirements.

**Layer separation (normative).** The Core defines the measurement calculus (what coherence is, how to compute $C_{\Sigma}$). Operational defines policy (when to accept, which parameters to use, how to maintain stability). Implementations MUST respect this boundary: Core math cannot be changed by policy, and policy cannot redefine Core constructs.

---

## 1 · Assumed Core Objects (for reference)

From the Core we use, without redefining:
- Axes $\{\alpha, \beta, \gamma\}$, contexts $\Omega_a$, articulations $O_a = A_a(\mathbf{C})$.
- Summaries $S_a = (d_a, p_a, \mathcal{H}_a, \mathcal{I}_a)$.
- Alignment ensembles $\mathcal{A}_{ab}$ and pairwise $\overline{\mathrm{Coh}}_{ab}$ with ensemble variance $\mathrm{Var}_{ab}$.
- Dimensional scores: $\alpha_c$ (pattern stability), $\beta_c$ (relational coherence), $\gamma_c$ (process stability).
- Aggregate coherence: $C_{\Sigma} = (\alpha_c \cdot \beta_c \cdot \gamma_c)^{1/3}$.
- Dimensional leverage: $\lambda_a = -\ln(\max(a_c, \varepsilon))$ and $\lambda_{\Sigma} = -\ln(C_{\Sigma})$.

---

## 2 · Parameter Registry (Policy)

All parameters MUST be fixed **before** observation and logged with the verdict.

### 2.1 Coherence and Aggregation (from Core §0)
- $\theta \in [0,1]$ — mixture weight for $\Delta_{\text{struct}}$ vs $\Delta_{\text{dist}}$ (default **0.7**).
- $\lambda_{\alpha} > 0$ — $\alpha$-axis stability sensitivity (default **4.0**).
- $\lambda_{\beta} > 0$ — $\beta$-axis relational sensitivity (default **4.0**).
- $\lambda_{\gamma} > 0$ — $\gamma$-axis process sensitivity (default **4.0**).
- $\Delta n > 0$ — minimum block size for block bootstrap when temporal/spatial correlation present (default **50**).
- $\varepsilon > 0$ — numerical floor for clamping scores before aggregation and $\ln(\cdot)$ operations (default **1×10⁻⁵**).
- $\Theta \in (0,1]$ — pass threshold on $C_{\Sigma}$ lower confidence bound (default **0.80** for general use, **0.90** for self-application).

### 2.2 Stability and Witness Floors (Operational Policy)
- $\tau_{\text{braid}} > 0$ — acceptance tolerance for Braided Interchange Witness $\delta_{\text{MFI}}$ (default **1×10⁻³**).
- $Z_{\text{crit}} > 0$ — critical threshold for out-of-distribution detection (default **0.95** quantile, approximately 2σ).
- $\tau_{\text{var}} > 0$ — maximum acceptable ensemble variance $\mathrm{Var}_{ab}$ (default **2×10⁻²**).
- $\tau_{\text{L}} > 0$ — maximum allowed Lipschitz distortion $L_{\text{align}}$ per alignment (default **20**).
- $\tau_{\delta} > 0$ — maximum allowed scale drift for $\gamma$-Equivariance Witness (default **0.05**).
- $n_{\min} > 0$ — minimum sample size per axis (default **32** observations).
- $\Delta t$ — temporal step size for $\gamma$-axis process stability (phenomenon-specific, MUST be recorded).
- $d_{\gamma}$ — ground metric for Wasserstein distance in $\gamma$-axis (MUST be declared and recorded).

### 2.3 Sampling and Estimation (Bootstrap Policy)
- $N_{\text{boot}}$ — number of bootstrap resamples for confidence interval estimation (default **200**).
- $N_{\text{MFI}}$ — number of quadruple samples for Braided Interchange Witness (default **100**).
- CI level — confidence interval coverage probability (default **0.95** for 95% CI).

---

## 3 · Verification Protocol (Concrete Steps)

**Input:** Phenomenon $P$ with articulations $A_{\alpha}, A_{\beta}, A_{\gamma}$ producing observations $O_{\alpha}, O_{\beta}, O_{\gamma}$.

**Output:** Verdict (PASS/FAIL/FAIL_DEGENERATE), $C_{\Sigma}$ with CI, dimensional scores, witnesses, provenance bundle.

---

### Step 1: Observation and Summary Construction

1. **Articulate** phenomenon $P$ along each axis:
   - $O_{\alpha} = A_{\alpha}(P)$ (pattern observations)
   - $O_{\beta} = A_{\beta}(P)$ (relational observations)
   - $O_{\gamma} = A_{\gamma}(P)$ (process observations)

2. **Validate** minimum sample sizes:
   - Verify $|O_a| \ge n_{\min}$ (default 32) for each axis $a \in \{\alpha, \beta, \gamma\}$
   - If any $|O_a| < n_{\min}$, flag FAIL_DEGENERATE with reason "insufficient observations"

3. **Construct summaries** $S_a = (d_a, p_a, \mathcal{H}_a, \mathcal{I}_a)$ for each axis:
   - $d_a$: intrinsic dimension (via PCA, manifold learning, or declared metric)
   - $p_a$: empirical probability distribution over features
   - $\mathcal{H}_a$: Shannon entropy $-\sum_i p_a(i) \log p_a(i)$
   - $\mathcal{I}_a$: detected invariants or conserved quantities

4. **Record** summary schemas in provenance (feature types, binning, dimension estimation method).

---

### Step 2: Pairwise Alignment and Coherence

For each unordered pair $(a,b) \in \{(\alpha,\beta), (\beta,\gamma), (\gamma,\alpha)\}$:

1. **Apply alignment ensemble** $\mathcal{A}_{ab}$ with $|\mathcal{A}_{ab}| \ge 3$:
   - For each alignment method $\sigma \in \mathcal{A}_{ab}$:
     - Compute discrepancy: $\Delta(S_a, S_b; \sigma) = \theta \cdot \Delta_{\text{struct}} + (1-\theta) \cdot \Delta_{\text{dist}}$
     - Compute coherence: $\mathrm{Coh}(S_a, S_b; \sigma) = \exp(-\lambda_{\beta} \cdot \Delta(S_a, S_b; \sigma))$

2. **Aggregate over ensemble**:
   $$
   \overline{\mathrm{Coh}}_{ab} = \frac{1}{|\mathcal{A}_{ab}|} \sum_{\sigma \in \mathcal{A}_{ab}} \mathrm{Coh}(S_a, S_b; \sigma)
   $$

3. **Compute ensemble variance**:
   $$
   \mathrm{Var}_{ab} = \frac{1}{|\mathcal{A}_{ab}|} \sum_{\sigma} \big(\mathrm{Coh}(S_a, S_b; \sigma) - \overline{\mathrm{Coh}}_{ab}\big)^2
   $$

4. **Record** alignment specifications and Lipschitz bounds $L_{\text{align}}$ for each $\sigma$.

---

### Step 3: Dimensional Scores

**$\alpha$-axis (Pattern Stability):**
1. Generate perturbed summary $S'_{\alpha}$ via one of:
   - Re-run articulation with different seed
   - Disjoint split of observations
   - Bootstrap-jackknife (MUST use block bootstrap if temporal/spatial correlation present, block size $\ge \Delta n$)

2. Compute metric distance $d_{\alpha}(S_{\alpha}, S'_{\alpha})$ (e.g., Wasserstein distance between $p_{\alpha}$ and $p'_{\alpha}$)

3. Calculate:
   $$
   \alpha_c = \exp(-\lambda_{\alpha} \cdot d_{\alpha}(S_{\alpha}, S'_{\alpha}))
   $$

**$\beta$-axis (Relational Coherence):**
1. Use pairwise coherences from Step 2

2. Calculate geometric mean:
   $$
   \beta_c = (\overline{\mathrm{Coh}}_{\alpha\beta} \cdot \overline{\mathrm{Coh}}_{\beta\gamma} \cdot \overline{\mathrm{Coh}}_{\gamma\alpha})^{1/3}
   $$

**$\gamma$-axis (Process Stability):**
1. Obtain temporal observations $O_{\gamma}^{(t)}$ and $O_{\gamma}^{(t+\Delta t)}$ separated by time step $\Delta t$

2. Compute summaries $S_{\gamma}^{(t)}$ and $S_{\gamma}^{(t+\Delta t)}$

3. Calculate 1-Wasserstein distance with ground metric $d_{\gamma}$:
   $$
   \gamma_c = \exp(-\lambda_{\gamma} \cdot W_1^{(d_{\gamma})}(p_{\gamma}^{(t)}, p_{\gamma}^{(t+\Delta t)}))
   $$

---

### Step 4: Aggregate Coherence and Confidence Intervals

1. **Apply numerical floor** (prevent log singularities):
   - For each dimensional score: $a_c \leftarrow \max(a_c, \varepsilon)$ where $a \in \{\alpha, \beta, \gamma\}$

2. **Compute aggregate**:
   $$
   C_{\Sigma} = (\alpha_c \cdot \beta_c \cdot \gamma_c)^{1/3}
   $$

3. **Bootstrap confidence interval**:
   - For $i = 1$ to $N_{\text{boot}}$ (default 200):
     - Resample observation indices with replacement
     - Recompute all dimensional scores and $C_{\Sigma}^{(i)}$
   - Compute percentiles: $\text{CI}_{\text{lo}} = \text{2.5th percentile}$, $\text{CI}_{\text{hi}} = \text{97.5th percentile}$

4. **Compute dimensional leverage**:
   $$
   \lambda_a = -\ln(\max(a_c, \varepsilon)), \quad \lambda_{\Sigma} = \frac{1}{3}(\lambda_{\alpha} + \lambda_{\beta} + \lambda_{\gamma})
   $$

---

### Step 5: Witness Verification

Execute all witnesses in parallel (failure of any witness leads to FAIL_DEGENERATE):

**W1: Braided Interchange Witness** (tests C≡ Axiom C5′, see §4.1)

**W2: Axis-Permutation Witness** (tests Core Property P1, see §4.2)

**W3: Role-Gauge Witness** (tests C≡ Axiom C2, see §4.3)

**W4: Scale-Equivariance Witness** (tests Core Axiom A3, see §4.4)

**W5: Variance and Lipschitz Witnesses** (guards against degeneracy, see §4.5)

Detailed witness protocols in §4.

---

### Step 6: Out-of-Distribution Detection

1. **Compute stability statistic** $Z_t$ against reference distribution (see §10):
   $$
   Z_t = \frac{|C_{\Sigma}^{(t)} - \text{median}(\text{ref})|}{1.4826 \cdot \text{MAD}(\text{ref})}
   $$

2. **Flag OOD** if $Z_t \ge Z_{\text{crit}}$ (default 0.95)

---

### Step 7: Verdict Logic

1. **Check witness gates**:
   - If any witness fails → **FAIL_DEGENERATE** (with specific witness failure reason)

2. **Check coherence threshold**:
   - If $\text{CI}_{\text{lo}}(C_{\Sigma}) \ge \Theta$ → **PASS**
   - Otherwise → **FAIL**

3. **Check OOD status**:
   - If $Z_t \ge Z_{\text{crit}}$ → trigger controller state transition (§5) to LOCKDOWN, attach OOD flag to verdict

4. **Construct provenance bundle** (§7)

5. **Return verdict** with full outputs (Core §5 specification)

---

## 4 · Witnesses (Degeneracy Guards)

Witnesses are **monitors**, not metrics. Failure of any witness invalidates the run irrespective of $C_{\Sigma}$.

---

### 4.1 Braided Interchange Witness (Tests C≡ Axiom C5′)

**Purpose.** Empirically verify that the braided interchange axiom $\varphi_{ab}$ holds for the measurement corpus. This tests whether the triadic structure respects the natural isomorphism required by the C-Calculus.

**Protocol:**

1. **Define corpus.** Let $\mathcal{C}$ be the set of measurable objects in the phenomenon (e.g., for code: functions/modules; for specs: sections/definitions; for data: observation clusters).

2. **Sample quadruples.** Draw $N = N_{\text{MFI}}$ (default 100) independent quadruples $(x, y, z, w)$ uniformly from $\mathcal{C}^4$.

3. **Compute compositions** for each quadruple using the declared binary operations $\odot_a$:
   - Left-nested: $L = (x \odot_a y) \odot_b (z \odot_a w)$
   - Right-nested: $R = (x \odot_b z) \odot_a (y \odot_b w)$

4. **Normalize** both expressions using the declared normalization strategy $\mathrm{NF}[\cdot]$ (Core §4, C≡ §4):
   - $L_{\text{norm}} = \mathrm{NF}[L]$
   - $R_{\text{norm}} = \mathrm{NF}[R]$

5. **Measure discrepancy** using the canonical ground metric $d_{\text{canon}}$ (same metric family used for summaries):
   $$
   \delta_{\text{MFI}}^{(i)} = d_{\text{canon}}(L_{\text{norm}}, R_{\text{norm}})
   $$

6. **Aggregate** over all $N$ samples:
   - Compute mean $\overline{\delta}_{\text{MFI}}$, median $\tilde{\delta}_{\text{MFI}}$
   - Bootstrap 95% CI on the mean: $[\delta_{\text{MFI}}^{\text{lo}}, \delta_{\text{MFI}}^{\text{hi}}]$

7. **Gate condition:**
   $$
   \delta_{\text{MFI}}^{\text{hi}} \le \tau_{\text{braid}} \quad \text{(default } 10^{-3}\text{)}
   $$
   If violated → FAIL_DEGENERATE with reason "braided interchange violation"

**Implementation notes:**
- For code corpus: $x, y, z, w$ are function/module pairs; $\odot_a$ is composition/dependency
- For spec corpus: $x, y, z, w$ are section/definition pairs; $\odot_a$ is cross-reference/dependency
- The normalization strategy $\mathrm{NF}[\cdot]$ MUST be recorded in provenance (typically: canonical ordering + idempotent reduction)

---

### 4.2 Axis-Permutation Witness (Tests Core Property P1)

**Purpose.** Verify that $C_{\Sigma}$ is invariant under permutations of axis labels $\{\alpha, \beta, \gamma\}$ (S₃ symmetry).

**Protocol:**

1. **Baseline run.** Compute $C_{\Sigma}$ with canonical axis assignment $(\alpha, \beta, \gamma)$ using a fixed random seed.

2. **Permuted runs.** For each of the 5 non-identity permutations $\pi \in S_3$:
   - Relabel axes: $(\alpha', \beta', \gamma') = (\pi(\alpha), \pi(\beta), \pi(\gamma))$
   - Recompute $C_{\Sigma}^{(\pi)}$ using the **same seeds and resampling indices** as baseline
   - Compute bootstrap CI for $C_{\Sigma}^{(\pi)}$

3. **Gate condition.** For each permutation $\pi$:
   $$
   C_{\Sigma}^{(\pi)} \in [\text{CI}_{\text{lo}}^{\text{(baseline)}}, \text{CI}_{\text{hi}}^{\text{(baseline)}}]
   $$
   
4. **Aggregate check.** Additionally verify that pairwise coherences satisfy:
   $$
   \overline{\mathrm{Coh}}_{\pi(a)\pi(b)} \in [\text{CI}_{\text{lo}}^{(ab)}, \text{CI}_{\text{hi}}^{(ab)}]
   $$
   for all pairs $(a,b)$.

5. If any permuted run falls outside baseline CI → FAIL_DEGENERATE with reason "S₃ invariance violation"

---

### 4.3 Role-Gauge Witness (Tests C≡ Axiom C2)

**Purpose.** Verify that measurement is invariant under role rotation $\rho: (r, a) \mapsto (r', a)$ where $r \in \{R, I, E\}$ and $\rho^3 = \text{id}$.

**Protocol:**

1. **Baseline articulation.** Perform standard articulation with role assignment $\rho_0$ (typically: Resource → $\alpha$, Interaction → $\beta$, Experience → $\gamma$).

2. **Rotated articulation.** Apply role rotation:
   - $\rho_1 = \rho \circ \rho_0$ (one step: R→I→E→R)
   - Re-articulate phenomenon with rotated role-axis mapping
   - Compute $C_{\Sigma}^{(\rho_1)}$ using same seeds

3. **Gate condition:**
   $$
   |C_{\Sigma}^{(\rho_1)} - C_{\Sigma}^{(\rho_0)}| \le \text{max}(\text{CI}_{\text{hi}} - C_{\Sigma}^{(\rho_0)}, C_{\Sigma}^{(\rho_0)} - \text{CI}_{\text{lo}})
   $$
   (i.e., rotated result must fall within baseline confidence interval)

4. **Extended check (optional).** Verify $\rho_2 = \rho^2 \circ \rho_0$ also satisfies gate condition.

5. If gate violated → FAIL_DEGENERATE with reason "role gauge violation"

**Implementation note:** Role rotation is a **presentation transformation**, not a change in measurement. The articulation functions $A_a$ may be re-interpreted (e.g., swapping which observations are labeled "pattern" vs "relation"), but the underlying observations and summaries remain structurally identical.

---

### 4.4 Scale-Equivariance Witness (Tests Core Axiom A3)

**Purpose.** Verify that coherence is stable under uniform scale transformations.

**Protocol ($\gamma$-axis temporal scaling):**

1. **Baseline.** Compute $\gamma_c$ with declared time step $\Delta t$.

2. **Scale perturbations.** Compute $\gamma_c$ with perturbed time steps:
   - $\Delta t' = 0.8 \cdot \Delta t$ (20% compression)
   - $\Delta t' = 1.2 \cdot \Delta t$ (20% expansion)

3. **Measure drift:**
   $$
   \delta_{\text{scale}} = \max\big(|\gamma_c^{(0.8)} - \gamma_c|, |\gamma_c^{(1.2)} - \gamma_c|\big)
   $$

4. **Gate condition:**
   $$
   \delta_{\text{scale}} \le \tau_{\delta} \quad \text{(default } 0.05\text{)}
   $$

5. If violated → FAIL_DEGENERATE with reason "scale equivariance violation"

**Alternative (spatial scaling).** For spatial contexts, apply uniform dilation $\phi(x) = s \cdot x$ to all observations and verify $|C_{\Sigma}(\phi(O)) - C_{\Sigma}(O)| \le \tau_{\delta}$.

---

### 4.5 Variance and Lipschitz Witnesses

**Purpose.** Guard against degenerate alignment ensembles and unbounded distortions.

**Variance witness:**
- For each pair $(a,b)$, verify $\mathrm{Var}_{ab} \ge \tau_{\text{var}}^{\text{min}}$ (default $10^{-4}$, prevents collapsed ensemble)
- And $\mathrm{Var}_{ab} \le \tau_{\text{var}}^{\text{max}}$ (default $2 \times 10^{-2}$, prevents unstable ensemble)
- If violated → FAIL_DEGENERATE with reason "ensemble variance out of bounds"

**Lipschitz witness:**
- For each alignment $\sigma \in \mathcal{A}_{ab}$, verify $L_{\text{align}}^{(\sigma)} \le \tau_{\text{L}}$ (default 20)
- If any alignment has $L_{\text{align}} > \tau_{\text{L}}$ → exclude from ensemble and flag warning
- If $|\mathcal{A}_{ab}| < 3$ after exclusions → FAIL_DEGENERATE with reason "insufficient valid alignments"

---

## 5 · State Machine (Controller States)

**Purpose.** A minimal controller that adapts solver ensembles and budgets to maintain verification stability without changing Core mathematics.

---

### 5.1 States

**HANDSHAKE (Calibration)**
- **Purpose:** Establish baseline ensemble and parameter selection
- **Action:** Vary alignment priors and regularization to reduce $\mathrm{Var}_{ab}$ below $\tau_{\text{var}}$
- **Budget:** High computational budget, exploratory ensembles

**OPTIMIZE (Production)**
- **Purpose:** Steady-state verification with locked parameters
- **Action:** Use high-fidelity ensembles, maintain default budgets
- **Budget:** Standard computational budget

**REINFLATE (Robustification)**
- **Purpose:** Respond to increased variance or CI width by expanding robustness
- **Action:** Increase regularization, use robust cost functions, broaden priors
- **Budget:** Elevated computational budget

**LOCKDOWN (Monitor Only)**
- **Purpose:** Respond to out-of-distribution detection by freezing and monitoring
- **Action:** Reuse last known-good alignments, compute conservative lower-bound $\overline{\mathrm{Coh}}_{ab}$ only
- **Budget:** Minimal computational budget

**MINIMAL_INFO (Coarse Mode)**
- **Purpose:** Emergency fallback for resource-constrained or ambiguous contexts
- **Action:** Use clustering, coarse alignment ensembles, relaxed witness tolerances
- **Budget:** Minimal computational budget

---

### 5.2 State Transition Rules

**Initial state:** Always start in **HANDSHAKE** for new phenomena.

**Transition table:**

| From | To | Trigger | Action |
|------|-----|---------|--------|
| HANDSHAKE | OPTIMIZE | $\mathrm{Var}_{ab} < \tau_{\text{var}}$ for all pairs (3 consecutive runs) | Lock ensemble specs, enter production mode |
| OPTIMIZE | REINFLATE | CI width $> 0.15$ OR $\mathrm{Var}_{ab} > \tau_{\text{var}}$ for any pair | Increase regularization, expand robustness |
| OPTIMIZE | LOCKDOWN | $Z_t \ge Z_{\text{crit}}$ (OOD detected) | Freeze ensembles, monitor only |
| LOCKDOWN | REINFLATE | $Z_t < Z_{\text{crit}}$ for 5 consecutive runs | Resume calibration with expanded robustness |
| REINFLATE | OPTIMIZE | $\mathrm{Var}_{ab} < \tau_{\text{var}}$ for all pairs (2 consecutive runs) | Return to production mode |
| * (any) | MINIMAL_INFO | Manual override OR critical resource constraint | Enter coarse mode |
| MINIMAL_INFO | HANDSHAKE | Resource constraint lifted | Restart full calibration |

**Hysteresis:** All automatic transitions require $N$ consecutive trigger events (default $N=2$) to prevent oscillation, **except** OPTIMIZE → LOCKDOWN which is immediate (OOD must trigger instant response).

**Logging:** Every state transition MUST be logged in provenance with timestamp, trigger reason, and previous/current state.

---

## 6 · Verdict Logic (Normative Decision Rules)

**Input:** All Core outputs ($\alpha_c, \beta_c, \gamma_c, C_{\Sigma}, \text{CI}_{\text{lo}}, \text{CI}_{\text{hi}}$), all witness results, $Z_t$ statistic.

**Output:** One of {PASS, FAIL, FAIL_DEGENERATE}, with OOD flag if applicable.

---

### Decision Flow

**Step 1: Witness gate**
```

IF any witness fails THEN
RETURN FAIL_DEGENERATE(reason=<specific witness failure>)
END IF

```
**Step 2: Coherence threshold**
```

IF CI_lo(C_Σ) ≥ Θ THEN
verdict ← PASS
ELSE
verdict ← FAIL
END IF

```
**Step 3: OOD flag**
```

IF Z_t ≥ Z_crit THEN
SET ood_flag ← TRUE
TRIGGER controller_transition(current_state → LOCKDOWN)
ELSE
SET ood_flag ← FALSE
END IF

```
**Step 4: Return**
```

RETURN (verdict, ood_flag, C_Σ, CI, dimensional_scores, witnesses, provenance)

```
---

### Verdict Semantics

**PASS:**
- $\text{CI}_{\text{lo}}(C_{\Sigma}) \ge \Theta$ (default 0.80, or 0.90 for self-application)
- All witnesses pass
- May have OOD flag (indicates distribution shift but not failure)

**FAIL:**
- $\text{CI}_{\text{lo}}(C_{\Sigma}) < \Theta$
- All witnesses pass
- Indicates insufficient coherence, but measurement is valid

**FAIL_DEGENERATE:**
- At least one witness fails
- Indicates measurement itself is unreliable (degenerate alignment ensemble, violated braiding, etc.)
- $C_{\Sigma}$ value MUST NOT be trusted even if numerically high

---

## 7 · Reproducibility and Provenance (Normative Requirements)

**Requirement.** Every verification MUST produce a **provenance bundle** sufficient for third-party exact recomputation.

---

### 7.1 Required Provenance Contents

**Phenomenon specification:**
- Unique identifier for phenomenon $P$
- Version/timestamp of phenomenon (if applicable)

**Context declarations:**
- Structured schemas for $\Omega_{\alpha}, \Omega_{\beta}, \Omega_{\gamma}$
- Feature types, binning strategies, metric declarations
- Sample sizes $|O_{\alpha}|, |O_{\beta}|, |O_{\gamma}|$

**Parameter snapshot:**
- All parameters from §2.1 and §2.2 (exact values used, not defaults)
- Controller state at time of verification
- Threshold values ($\Theta, \tau_{\text{braid}}, Z_{\text{crit}}$, etc.)

**Algorithmic specifications:**
- Alignment ensemble $\mathcal{A}_{ab}$ for each pair (method names, hyperparameters)
- Summary construction algorithms (dimension estimation method, binning, invariant detection)
- Normalization strategy $\mathrm{NF}[\cdot]$ used for MFI witness
- Bootstrap protocol (resampling scheme, block size if applicable)

**Randomness control:**
- Master random seed
- Per-step seeds (bootstrap, alignment solvers, witness sampling)
- Resampling indices (for exact CI replication)

**Computational environment:**
- Software versions (TSC implementation, dependencies)
- Hardware characteristics (if performance-sensitive)

**Witness results:**
- All witness statistics (means, medians, CIs)
- Pass/fail status for each witness
- Specific failure reasons if FAIL_DEGENERATE

**OOD tracking:**
- Reference distribution (all historical $C_{\Sigma}$ values or summary statistics)
- $Z_t$ statistic and percentile rank

---

### 7.2 Provenance Bundle Format

**Recommended format:** YAML or JSON with schema validation.

**Minimal example:**
```yaml
tsc_verification:
  version: "2.2.2"
  timestamp: "2024-01-15T14:32:00Z"
  phenomenon_id: "TSC-repo-v2.2.2"
  
  parameters:
    theta: 0.7
    lambda_alpha: 4.0
    lambda_beta: 4.0
    lambda_gamma: 4.0
    epsilon: 1.0e-5
    Theta: 0.90
    tau_braid: 1.0e-3
    Z_crit: 0.95
    
  results:
    C_sigma: 0.943
    CI: [0.917, 0.961]
    alpha_c: 0.956
    beta_c: 0.932
    gamma_c: 0.941
    verdict: "PASS"
    ood_flag: false
    
  witnesses:
    braided_interchange:
      delta_MFI_mean: 0.00072
      delta_MFI_CI: [0.00051, 0.00089]
      status: "PASS"
    S3_invariance:
      max_deviation: 0.011
      status: "PASS"
    role_gauge:
      rho1_difference: 0.008
      status: "PASS"
    scale_equivariance:
      delta_scale: 0.032
      status: "PASS"
      
  controller_state: "OPTIMIZE"
  
  seeds:
    master: 42
    bootstrap: 123
    MFI_sampling: 456
```

-----

## 8 · Diagnostics and Leverage Interpretation

**Purpose.** Use dimensional leverage (Core §8) to guide operational decisions and resource allocation.

-----

### 8.1 Leverage-Driven Budget Allocation

**Computation.** For each dimension $a \in {\alpha, \beta, \gamma}$:
$$
\lambda_a = -\ln(\max(a_c, \varepsilon))
$$

**Normalized allocation weights (Recognition Flow $R_C$):**
$$
R_C = \left(\frac{\lambda_{\alpha}}{\lambda_{\Sigma}}, \frac{\lambda_{\beta}}{\lambda_{\Sigma}}, \frac{\lambda_{\gamma}}{\lambda_{\Sigma}}\right)
$$
where $\lambda_{\Sigma} = (\lambda_{\alpha} + \lambda_{\beta} + \lambda_{\gamma})/3$.

**Allocation policy:**

- If $\lambda_{\alpha}$ dominates ($> 0.4$ of total leverage) → increase $\alpha$-axis bootstrap depth, expand resampling
- If $\lambda_{\beta}$ dominates → expand alignment ensemble $|\mathcal{A}_{ab}|$, increase solver fidelity
- If $\lambda_{\gamma}$ dominates → refine temporal sampling $\Delta t$, increase observation density

-----

### 8.2 Diagnostic Reporting

**For each verification, report:**

1. **Leverage breakdown:**
   
   ```
   λ_α = 0.045  (23% of total)  ← Pattern stability high
   λ_β = 0.071  (36% of total)  ← Relational coherence moderate
   λ_γ = 0.061  (31% of total)  ← Process stability moderate
   λ_Σ = 0.059  (aggregate)
   ```
1. **Bottleneck identification:**

- Dimension with highest $\lambda_a$ is the **coherence bottleneck**
- Recommend targeted improvements for that dimension

1. **Trend analysis:**

- Track $\lambda_a$ across versions/time
- Flag if any dimension shows increasing leverage (degrading coherence)

-----

### 8.3 Energy-Coherence Duality

**Interpretation.** The aggregate leverage $\lambda_{\Sigma}$ can be viewed as **coherence energy**:
$$
E_{\Sigma} = \lambda_{\Sigma} = -\ln(C_{\Sigma})
$$

**Minimization equivalence:** Minimizing $E_{\Sigma}$ (energy) is equivalent to maximizing $C_{\Sigma}$ (coherence).

**Use case:** Optimization algorithms can target $\lambda_{\Sigma}$ directly as an additive objective function (easier than multiplicative $C_{\Sigma}$).

-----

## 9 · Controller State Transitions (Extended Policy)

**Purpose.** Define detailed transition logic and hysteresis to prevent state oscillation.

-----

### 9.1 Transition Conditions (Detailed)

**HANDSHAKE → OPTIMIZE**

- **Trigger:** $\mathrm{Var}*{ab} < \tau*{\text{var}}$ for all three pairs $(ab) \in {(\alpha\beta), (\beta\gamma), (\gamma\alpha)}$ for $N=3$ consecutive runs
- **Pre-check:** All witnesses must have passed in the last run
- **Action on transition:**
  - Lock current alignment ensemble specs (freeze hyperparameters)
  - Record baseline $C_{\Sigma}$ distribution (for OOD reference)
  - Switch to production budget (standard solver tolerances)

**OPTIMIZE → REINFLATE**

- **Trigger (either):**
  - CI width $> 0.15$ (large uncertainty)
  - OR $\mathrm{Var}*{ab} > \tau*{\text{var}}$ for any pair (unstable ensemble)
  - (Both conditions checked for $N=2$ consecutive runs)
- **Action on transition:**
  - Increase solver regularization by 2× (e.g., entropic OT: $\varepsilon \leftarrow 2\varepsilon$)
  - Add robust cost functions to ensemble (e.g., Huber loss variants)
  - Expand priors (e.g., increase prior weight by 50%)
  - Increase bootstrap depth to $1.5 \times N_{\text{boot}}$

**OPTIMIZE → LOCKDOWN**

- **Trigger:** $Z_t \ge Z_{\text{crit}}$ (out-of-distribution detected)
- **Hysteresis:** **None** (immediate transition for safety)
- **Action on transition:**
  - Freeze all alignment ensembles (use last known-good)
  - Switch to lower-bound computation only (conservative estimates)
  - Increase logging verbosity
  - Alert: “OOD detected, entering monitoring mode”

**LOCKDOWN → REINFLATE**

- **Trigger:** $Z_t < Z_{\text{crit}}$ for $N=5$ consecutive runs (distribution has stabilized)
- **Action on transition:**
  - Resume full alignment ensemble evaluation
  - Maintain elevated robustness (from REINFLATE policy)
  - Gradually reduce regularization over next 3 runs if stability holds

**REINFLATE → OPTIMIZE**

- **Trigger:** $\mathrm{Var}*{ab} < \tau*{\text{var}}$ for all pairs for $N=2$ consecutive runs
- **Action on transition:**
  - Restore standard solver tolerances
  - Return to baseline priors
  - Resume standard budget

**Manual override: * → MINIMAL_INFO**

- **Trigger:** Manual flag OR resource constraint (e.g., wall time exceeded, memory limit)
- **Action:**
  - Switch to coarse alignment methods (k-means, nearest neighbor)
  - Reduce bootstrap depth to $0.5 \times N_{\text{boot}}$
  - Relax witness tolerances by 2× (e.g., $\tau_{\text{braid}} \leftarrow 2 \tau_{\text{braid}}$)
  - Flag all results as “COARSE_MODE” in provenance

-----

### 9.2 Hysteresis and Debouncing

**Rationale.** Prevent rapid state oscillation due to noise in $\mathrm{Var}_{ab}$ or CI estimates.

**Mechanism:** Most transitions require $N$ consecutive trigger events (default $N=2$).

**Exception:** OOD detection (OPTIMIZE → LOCKDOWN) is **immediate** ($N=1$) because distribution shifts require instant response.

**Debouncing window:** When a trigger occurs but is not yet consecutive, start a window of length $W$ runs (default $W=5$). If trigger does not recur within window, reset counter.

-----

## 10 · Out-of-Distribution Detection (Normative Method)

**Purpose.** Detect when current observations diverge from established patterns, indicating potential distribution shift, concept drift, or measurement context change.

-----

### 10.1 Reference Distribution Maintenance

**Initialization (HANDSHAKE state):**

- Collect first $K$ verification results (default $K=10$)
- Form initial reference distribution: $\text{ref} = {C_{\Sigma}^{(1)}, \ldots, C_{\Sigma}^{(K)}}$

**Rolling window (OPTIMIZE state):**

- Maintain fixed-size window of last $W$ results (default $W=20$)
- For each new verification, add $C_{\Sigma}^{(t)}$ and remove oldest if $|\text{ref}| > W$

**Robust statistics:**

- Compute $\text{median}(\text{ref})$ and $\text{MAD}(\text{ref})$ (median absolute deviation)
- MAD is robust to outliers: $\text{MAD} = \text{median}(|C_{\Sigma}^{(i)} - \text{median}(\text{ref})|)$

-----

### 10.2 Stability Statistic Computation

**Robust z-score (default method):**
$$
Z_t = \frac{|C_{\Sigma}^{(t)} - \text{median}(\text{ref})|}{1.4826 \cdot \text{MAD}(\text{ref})}
$$

The factor $1.4826$ scales MAD to match standard deviation for Gaussian distributions.

**Alternative (small sample, $|\text{ref}| < 10$):** Bootstrap percentile method:

1. Bootstrap resample $\text{ref}$ to generate 1000 samples
1. Compute percentile rank of $C_{\Sigma}^{(t)}$ in bootstrap distribution
1. $Z_t = |\text{percentile rank} - 0.5| \times 2$ (distance from median, normalized to [0,1])

-----

### 10.3 OOD Gate and Actions

**Gate condition:**
$$
Z_t \ge Z_{\text{crit}} \quad \text{(default } Z_{\text{crit}} = 0.95 \text{, approximately 2σ)}
$$

**Actions when gate triggered:**

1. **Flag verdict** with OOD status (even if PASS)
1. **Trigger controller transition** to LOCKDOWN (§5)
1. **Log diagnostic info:**

- Current $C_{\Sigma}^{(t)}$ and $Z_t$
- Reference distribution statistics (median, MAD, range)
- Hypothesis: “Possible distribution shift or context change”

1. **Recommendation:** Investigate phenomenon for changes (new data sources, modified articulations, environmental drift)

**Recovery:** OOD flag is cleared when $Z_t < Z_{\text{crit}}$ for 5 consecutive runs.

-----

## 11 · Reflexive Self-Application (Meta-Verification)

**Purpose.** TSC defines coherence and **applies this definition to itself**. This section specifies how to measure $C_{\Sigma}(\text{TSC})$ across releases.

-----

### 11.1 Purpose and Scope

**Reflexive self-application** validates the TSC framework by measuring its own coherence. This is an empirical test of:

- **C≡ Axiom C1:** Self-application of cohering yields cohering ($\mathbf{C} \odot_a \mathbf{C} = \mathbf{C}$)
- **Core Axiom A4:** Self-articulation stability (applying $A_a$ twice should give results equivalent to $A_a(\mathbf{C})$)

**Not circularity.** The measurement calculus (Core) is independent of the measured object. We apply TSC’s coherence measurement to TSC’s artifacts (specs, code, documentation). The framework and the phenomenon are distinct.

**Release requirement.** Every TSC release MUST include a self-coherence report ($C_{\Sigma}(\text{TSC})$) in the release notes.

-----

### 11.2 Articulation of TSC as $\alpha/\beta/\gamma$

Treat the living TSC repository and specification set as a triadic phenomenon:

**$\alpha$-axis (Pattern Stability):**

- **Observations $O_{\alpha}$:** All specification files (`.md`), formal schemas (JSON/YAML), normative diagrams
- **Summary $S_{\alpha}$:**
  - $d_{\alpha}$: Embedding dimension of term vectors (via TF-IDF or word2vec on spec corpus)
  - $p_{\alpha}$: Distribution over concept classes (e.g., “axiom”, “parameter”, “witness”, “protocol”)
  - $\mathcal{H}_{\alpha}$: Entropy of term usage (uniform usage → high entropy, jargon-heavy → low entropy)
  - $\mathcal{I}_{\alpha}$: Detected invariants (e.g., consistent notation, preserved formal structure)

**$\beta$-axis (Relational Coherence):**

- **Observations $O_{\beta}$:** Cross-reference graph (section citations), dependency graph (Core → Operational → C≡), term co-occurrence matrix
- **Summary $S_{\beta}$:**
  - $d_{\beta}$: Graph diameter or effective dimension of citation network
  - $p_{\beta}$: Distribution over edge types (“defines”, “uses”, “tests”, “extends”)
  - $\mathcal{H}_{\beta}$: Entropy of connection patterns (well-connected → high entropy, siloed → low entropy)
  - $\mathcal{I}_{\beta}$: Preserved symmetries (e.g., S₃ symmetry in axis treatment, bidirectional citations)

**$\gamma$-axis (Process Stability):**

- **Observations $O_{\gamma}$:** Version history (git commits), change logs, controller state transitions, witness statistics across releases
- **Summary $S_{\gamma}$:**
  - $d_{\gamma}$: Dimension of trajectory embedding (e.g., PCA on change vectors)
  - $p_{\gamma}$: Distribution over change types (“refactor”, “bugfix”, “extension”, “clarification”)
  - $\mathcal{H}_{\gamma}$: Entropy of state transitions (diverse changes → high entropy, narrow focus → low entropy)
  - $\mathcal{I}_{\gamma}$: Conserved quantities (e.g., parameter count, witness count, Core axiom count)

-----

### 11.3 Summary Construction for TSC

**α-axis summary (Pattern):**

1. **Extract corpus:** Concatenate all `.md` spec files (C≡, Core, Operational)
1. **Tokenize:** Extract terms (n-grams, n=1 to 3)
1. **Compute $d_{\alpha}$:** PCA or manifold learning on term co-occurrence matrix → intrinsic dimension
1. **Compute $p_{\alpha}$:** Empirical distribution over concept classes (label terms via regex or manual tagging)
1. **Compute $\mathcal{H}_{\alpha}$:** Shannon entropy of $p_{\alpha}$
1. **Detect $\mathcal{I}_{\alpha}$:** Check for notation consistency (e.g., all $\lambda$ parameters use same symbol), structural invariants (e.g., all sections have Purpose statement)

**β-axis summary (Relation):**

1. **Build citation graph:** Parse all cross-references (e.g., “see Core §4”, “C≡ Axiom C2”)
1. **Compute $d_{\beta}$:** Graph diameter or effective dimension via spectral methods
1. **Compute $p_{\beta}$:** Distribution over edge types (classify citations as “defines”, “uses”, “tests”, “extends”)
1. **Compute $\mathcal{H}_{\beta}$:** Entropy of edge type distribution
1. **Detect $\mathcal{I}_{\beta}$:** Verify S₃ symmetry (e.g., axis names ${\alpha,\beta,\gamma}$ appear with equal frequency), check for orphaned sections (no incoming citations)

**γ-axis summary (Process):**

1. **Extract version history:** All commits between previous release and current
1. **Compute $d_{\gamma}$:** PCA on change vectors (e.g., lines added/deleted per file)
1. **Compute $p_{\gamma}$:** Distribution over change types (classify commits via message parsing)
1. **Compute $\mathcal{H}_{\gamma}$:** Entropy of change type distribution
1. **Detect $\mathcal{I}_{\gamma}$:** Track conserved quantities (e.g., Core axiom count should remain stable, parameter count should grow slowly)

-----

### 11.4 Dimensional Scores and Aggregation

**Floors and thresholds (normative defaults for self-application):**

- $\Theta = 0.90$ (higher threshold for self-application than general use)
- $\varepsilon = 1 \times 10^{-5}$ (standard numerical floor)
- $\tau_{\text{braid}} = 1 \times 10^{-3}$ (standard MFI tolerance)

**α_c (Pattern Stability):**

- Compare current release summary $S_{\alpha}^{(t)}$ to previous release $S_{\alpha}^{(t-1)}$
- Compute Wasserstein distance $W_1(p_{\alpha}^{(t)}, p_{\alpha}^{(t-1)})$ over concept classes
- $\alpha_c = \exp(-\lambda_{\alpha} \cdot W_1)$ with $\lambda_{\alpha} = 4.0$

**β_c (Relational Coherence):**

- For each pair $(a,b) \in {(\alpha,\beta), (\beta,\gamma), (\gamma,\alpha)}$:
  - Apply alignment ensemble (e.g., graph matching, co-occurrence alignment, structural correspondence)
  - Compute $\overline{\mathrm{Coh}}_{ab}$
- $\beta_c = (\overline{\mathrm{Coh}}*{\alpha\beta} \cdot \overline{\mathrm{Coh}}*{\beta\gamma} \cdot \overline{\mathrm{Coh}}_{\gamma\alpha})^{1/3}$

**γ_c (Process Stability):**

- Compare change distributions across release windows
- $\gamma_c = \exp(-\lambda_{\gamma} \cdot W_1(p_{\gamma}^{(t-1 \to t)}, p_{\gamma}^{(t-2 \to t-1)}))$
- Measures stability of evolution pattern (consistent change types → high $\gamma_c$)

**Aggregate:**
$$
C_{\Sigma}(\text{TSC}) = (\alpha_c \cdot \beta_c \cdot \gamma_c)^{1/3}
$$

-----

### 11.5 Witness Verification for TSC

**Braided Interchange (TSC corpus):**

1. Sample quadruples of spec sections $(x, y, z, w)$ (e.g., “Core §2”, “Core §4”, “C≡ §1”, “Operational §3”)
1. Define composition $\odot_a$ as “logical dependency” (e.g., $x \odot_{\alpha} y$ = “section $x$ uses definitions from section $y$”)
1. Test: Does $(x \odot_{\alpha} y) \odot_{\beta} (z \odot_{\alpha} w) \cong (x \odot_{\beta} z) \odot_{\alpha} (y \odot_{\beta} w)$?
1. Implementation: Check if cross-references compose associatively (no circular or contradictory dependencies)
1. Gate: $\delta_{\text{MFI}} \le \tau_{\text{braid}}$

**S₃ invariance:**

1. Compute $C_{\Sigma}(\text{TSC})$ with standard axis assignment (Pattern=α, Relation=β, Process=γ)
1. Permute axis labels (e.g., Pattern=β, Relation=γ, Process=α)
1. Verify all permuted results within CI of reference

**ρ-invariance:**

1. Re-articulate TSC using different role perspectives:

- Baseline: Resource → α, Interaction → β, Experience → γ
- Rotated: Resource → β, Interaction → γ, Experience → α

1. Verify $C_{\Sigma}$ remains stable (within CI)

**Scale equivariance:**

1. Compute $\gamma_c$ with standard release window ($\Delta t$ = 1 release)
1. Compute $\gamma_c$ with expanded window ($\Delta t$ = 2 releases)
1. Verify $|\gamma_c^{(1)} - \gamma_c^{(2)}| \le \tau_{\delta}$

-----

### 11.6 Controller Policy for Self-Application

**Initial release (HANDSHAKE):**

- Establish baseline $C_{\Sigma}(\text{TSC})$
- Build reference distribution (requires at least 3 releases)
- Calibrate witness tolerances for spec corpus

**Production releases (OPTIMIZE):**

- Maintain $\text{CI}*{\text{lo}}(C*{\Sigma}(\text{TSC})) \ge 0.90$
- Track $\delta_{\text{MFI}}$ across versions (should remain stable or decrease)
- Monitor dimensional leverage to identify focus areas

**Major refactors (REINFLATE):**

- After structural changes (e.g., adding new axioms, reorganizing sections), re-calibrate
- Expand CI estimation depth (more bootstrap samples)
- Compare pre-refactor and post-refactor $C_{\Sigma}$ (should not decrease significantly)

**Recognition flow for TSC (leverage-driven):**

- If $\lambda_{\alpha}$ dominates → improve spec clarity (pattern dimension)
  - Action: Refactor definitions, add examples, improve notation consistency
- If $\lambda_{\beta}$ dominates → improve cross-references (relational dimension)
  - Action: Add forward/backward citations, resolve orphaned sections, verify dependency coherence
- If $\lambda_{\gamma}$ dominates → improve version continuity (process dimension)
  - Action: Write clearer change logs, maintain architectural stability, document migrations

-----

### 11.7 Release Gating and Report Format

**Verdict Gate (normative for TSC releases):**

- **MUST:** $\text{CI}*{\text{lo}}(C*{\Sigma}(\text{TSC})) \ge 0.90$
- **MUST:** All witnesses pass ($\delta_{\text{MFI}} \le \tau_{\text{braid}}$, S₃ variance acceptable, etc.)
- **MUST:** $Z_t < Z_{\text{crit}}$ (not OOD relative to previous releases)
- **SHOULD:** Publish comparative analysis vs. previous version (trend in $C_{\Sigma}$, dimensional leverage shifts)

If any MUST condition fails → **release is blocked** until resolved.

**Report format (include in release notes):**

```markdown
## TSC Self-Coherence Report (v2.2.2)

**Aggregate Coherence:** C_Σ(TSC) = 0.943 [CI: 0.917, 0.961]

**Dimensional Breakdown:**
- α_c (Pattern Stability): 0.956 → λ_α = 0.045 (23% of leverage)
- β_c (Relational Coherence): 0.932 → λ_β = 0.071 (36% of leverage)
- γ_c (Process Stability): 0.941 → λ_γ = 0.061 (31% of leverage)

**Witnesses:**
- Braided Interchange: δ_MFI = 0.00072 [CI: 0.00051, 0.00089] ✓ PASS
- S₃ Invariance: max deviation = 0.011 ✓ PASS
- ρ-Invariance: role rotation difference = 0.008 ✓ PASS
- Scale Equivariance: δ_scale = 0.032 ✓ PASS

**OOD Status:** Z_t = 0.43 (well within reference distribution) ✓ PASS

**Controller State:** OPTIMIZE

**Verdict:** ✓ PASS

**Trend vs. v2.2.1:**
- C_Σ increased from 0.921 to 0.943 (+2.4%)
- Relational coherence (β_c) improved significantly (0.912 → 0.932)
- Pattern and process dimensions remained stable

**Interpretation:** The v2.2.2 release shows strong internal coherence. The primary 
leverage is in relational coherence (36%), suggesting continued focus on cross-reference 
completeness and dependency clarity in future releases.
```

-----

## 12 · Release Witnessing (Normative Requirements)

**Purpose.** Every TSC release MUST include comprehensive verification of its own coherence and publish the results as part of the release documentation.

-----

### 12.1 Required Release Artifacts

**1. Self-coherence score:**

- $C_{\Sigma}(\text{TSC})$ with 95% CI
- Dimensional breakdown ($\alpha_c, \beta_c, \gamma_c$)
- Dimensional leverage ($\lambda_{\alpha}, \lambda_{\beta}, \lambda_{\gamma}, \lambda_{\Sigma}$)

**2. Witness results:**

- Braided Interchange: $\delta_{\text{MFI}}$ with CI and gate status
- S₃ Invariance: variance across permutations and gate status
- ρ-Invariance: role rotation test results and gate status
- Scale Equivariance: $\delta_{\text{scale}}$ and gate status
- Lipschitz/Variance: ensemble statistics and gate status

**3. OOD status:**

- $Z_t$ statistic relative to previous releases
- Reference distribution summary (median, MAD, range)
- Percentile rank of current release

**4. Controller state:**

- Current state (HANDSHAKE/OPTIMIZE/REINFLATE/LOCKDOWN/MINIMAL_INFO)
- State transitions since last release (with timestamps and reasons)
- Hysteresis counters (if applicable)

**5. Provenance bundle:**

- Complete reproducibility bundle per §7 (seeds, parameters, alignment specs)
- Git commit hash of exact spec version measured
- Measurement timestamp

**6. Comparative analysis:**

- Trend in $C_{\Sigma}$ over last 5 releases (chart or table)
- Dimensional leverage shifts (which dimension improved/degraded)
- Witness stability trends

-----

### 12.2 Release Gate (Normative Checklist)

Before tagging a release, verify:

- [ ] $\text{CI}*{\text{lo}}(C*{\Sigma}(\text{TSC})) \ge 0.90$ (MUST)
- [ ] All witnesses pass (MUST)
- [ ] $Z_t < Z_{\text{crit}}$ (not OOD) (MUST)
- [ ] Self-coherence report included in release notes (MUST)
- [ ] Provenance bundle published (SHOULD)
- [ ] Comparative analysis vs. previous release (SHOULD)

If any MUST condition fails, the release is **blocked** until the issue is resolved.

-----

### 12.3 Publication Format

**Recommended location:** `docs/releases/v{X.Y.Z}/self-coherence-report.md`

**Recommended format:** Markdown with embedded YAML data block (for machine readability).

**Minimal example:**

```markdown
# TSC Self-Coherence Report

**Release:** v2.2.2  
**Date:** 2024-01-15  
**Status:** ✓ PASS

## Aggregate Coherence

C_Σ(TSC) = **0.943** [CI: 0.917, 0.961]

## Dimensional Scores

| Dimension | Score | Leverage | % of Total |
|-----------|-------|----------|------------|
| α (Pattern) | 0.956 | 0.045 | 23% |
| β (Relation) | 0.932 | 0.071 | 36% |
| γ (Process) | 0.941 | 0.061 | 31% |

## Witnesses

| Witness | Result | Status |
|---------|--------|--------|
| Braided Interchange | δ_MFI = 0.00072 [0.00051, 0.00089] | ✓ PASS |
| S₃ Invariance | max_dev = 0.011 | ✓ PASS |
| ρ-Invariance | diff = 0.008 | ✓ PASS |
| Scale Equivariance | δ_scale = 0.032 | ✓ PASS |

## OOD Detection

Z_t = 0.43 (43rd percentile) → ✓ Within reference distribution

## Controller

**State:** OPTIMIZE  
**Transitions:** None since v2.2.1

## Trend Analysis

| Release | C_Σ | α_c | β_c | γ_c |
|---------|-----|-----|-----|-----|
| v2.2.0 | 0.905 | 0.938 | 0.889 | 0.921 |
| v2.2.1 | 0.921 | 0.945 | 0.912 | 0.937 |
| v2.2.2 | 0.943 | 0.956 | 0.932 | 0.941 |

**Interpretation:** Steady improvement across all dimensions. Relational coherence 
(β_c) showed largest gain (+2.0%), indicating successful effort to improve 
cross-reference completeness.

## Provenance

```yaml
tsc_self_verification:
  version: "2.2.2"
  git_commit: "a3f9c2d"
  timestamp: "2024-01-15T14:32:00Z"
  seeds:
    master: 42
    bootstrap: 123
    MFI: 456
  parameters:
    theta: 0.7
    lambda_alpha: 4.0
    lambda_beta: 4.0
    lambda_gamma: 4.0
    Theta: 0.90
  alignment_ensembles:
    alpha_beta: ["gromov_wasserstein", "entropic_ot", "structural_match"]
    beta_gamma: ["graph_matching", "spectral_align", "embedding_align"]
    gamma_alpha: ["dtw", "procrustes", "temporal_correlation"]
```

**Provenance bundle:** [`provenance-v2.2.2.yaml`](./provenance-v2.2.2.yaml)

---

**End — TSC Operational v2.2.2 (Normative Policy and Procedure).**
