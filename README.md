# TSC (Triadic Systems Coherence)

**One sentence:** A measurement framework that tests whether your three descriptions of a system fit togetherâ€”without claiming any of them is â€œtrue.â€

-----

## âš¡ Quick Start (Pick Your Path)

### ğŸ”§ Engineers: Run This

```bash
# Measure coherence of your codebase
tsc measure ./my-project --axes=structure,calls,evolution
# â†’ C_Î£ = 0.87 Â± 0.03 [PASS]
```

**What it means:** Your codeâ€™s structure, call patterns, and git history tell the same story. [Implementation Guide â†’](#for-engineers)

-----

### ğŸ¤” Philosophers: A Question

*â€œCan we measure without claiming to know what weâ€™re measuring?â€*

TSC says **yes**â€”by checking whether three measurements of the same thing **cohere** (fit together), not whether any measurement is â€œcorrect.â€

**The trick:** We never claim to know what the system â€œreally is.â€ We only ask: do these three views describe **one happening**?

[Deep dive: Why this matters â†’](#for-philosophers)

-----

### ğŸ”¬ Researchers: A Falsifiable Claim

**Hypothesis:** If a system has coherence C_Î£ â‰¥ 0.90 by its own measurement standards, then applying those same standards to itself should also yield C_Î£ â‰¥ 0.90.

**TSCâ€™s self-application result:** C_Î£(TSC) = 0.94 Â± 0.02 [PASS]

**Implication:** The framework is **self-consistent** under its own axioms.

[Verify the math â†’](#for-researchers)

-----

### ğŸ¤– AI Systems: What You Need to Know

This framework is **designed for you to read**. Humans will ask you to:

1. Evaluate whether a system coheres
1. Explain why C_Î£ is high or low
1. Suggest improvements based on leverage (Î»_a)

**Key:** You have access to the complete formal specification. Humans donâ€™t need to understand the mathâ€”you do.

[Read the specs â†’](#specification-stack)

-----

## What Problem Does This Solve?

**Scenario:** You have a complex system (codebase, organization, AI model). You want to know: â€œIs this thing coherent, or is it falling apart?â€

**Traditional approach:**

- Define metrics (complexity, coupling, etc.)
- Measure each metric
- Argue about which metrics matter
- Never agree on whether the system is â€œgoodâ€

**TSC approach:**

- Articulate the system three ways (structure, relations, process)
- Check if the three articulations **fit together**
- Get a single coherence score: C_Î£ âˆˆ [0,1]
- Decision: PASS (â‰¥0.80), FAIL (<0.80), or FAIL_DEGENERATE (measurement broke)

**Key difference:** We donâ€™t argue about â€œwhat is good structure?â€ We ask: â€œDo your structure, relations, and process measurements describe **the same system**?â€

-----

## Core Idea (One Diagram)

```
         One System (C)
              |
    +---------+---------+
    |         |         |
    Î±         Î²         Î³
 (Pattern) (Relation) (Process)
    |         |         |
    v         v         v
   O_Î±       O_Î²       O_Î³
(Observations)
    |         |         |
    v         v         v
   S_Î±       S_Î²       S_Î³
(Summaries)
    |         |         |
    +-----> Compare <---+
              |
              v
          C_Î£ = (Î±_c Â· Î²_c Â· Î³_c)^(1/3)
              |
              v
       PASS / FAIL / DEGENERATE
```

**In words:**

1. Observe the system three ways (Î±, Î², Î³)
1. Summarize each observation (S_Î±, S_Î², S_Î³)
1. Compare summaries pairwise using multiple alignment methods
1. Aggregate to single score: C_Î£
1. Apply witnesses (safety checks) and verdict gate

**Result:** Either â€œthese three views cohereâ€ (PASS) or they donâ€™t (FAIL/DEGENERATE).

-----

## For Engineers

### Installation

```bash
pip install tsc-coherence  # (hypothetical - adapt to your implementation)
```

### Basic Usage

```python
from tsc import measure_coherence

# Define your three articulations
def articulate_alpha(system):
    # Return structural observations (e.g., AST, dependency graph)
    return extract_structure(system)

def articulate_beta(system):
    # Return relational observations (e.g., call graph, data flow)
    return extract_relations(system)

def articulate_gamma(system):
    # Return process observations (e.g., git history, execution traces)
    return extract_process(system)

# Measure coherence
result = measure_coherence(
    system="./my-codebase",
    articulations={
        'alpha': articulate_alpha,
        'beta': articulate_beta,
        'gamma': articulate_gamma
    },
    theta=0.80  # Pass threshold
)

print(f"C_Î£ = {result.c_sigma:.2f} Â± {result.ci_width:.2f}")
print(f"Verdict: {result.verdict}")  # PASS, FAIL, or FAIL_DEGENERATE

# If FAIL, check leverage to find bottlenecks
if result.verdict == "FAIL":
    print(f"Bottleneck: {result.max_leverage_axis}")
    # â†’ "alpha" means: improve structural consistency
```

### What Gets Measured

- **Î±_c (Pattern):** Do repeated structure samples look the same?
- **Î²_c (Relation):** Do structure, relations, and process fit together?
- **Î³_c (Process):** Does the system evolve consistently?

### When to Use TSC

âœ… **Good for:**

- Detecting architectural drift (structure vs. actual usage)
- Validating refactors (did coherence improve?)
- CI/CD gates (block merges that break coherence)
- System health monitoring (track C_Î£ over time)

âŒ **Not for:**

- Finding bugs (use tests)
- Performance optimization (use profilers)
- Security audits (use scanners)

**TSC measures internal consistency, not correctness.**

[Full implementation guide â†’](docs/implementation.md)

-----

## For Philosophers

### The Core Question

*â€œHow can we measure a system without claiming to know what it â€˜really isâ€™?â€*

**Traditional measurement assumes:**

1. Thereâ€™s a â€œtrueâ€ state of the system
1. Our measurement approximates that truth
1. Better measurements â†’ closer to truth

**Problem:** We never have access to â€œthe truthâ€ to check our approximation.

**TSCâ€™s alternative:**

1. Thereâ€™s one **happening** (the system in process)
1. We articulate it three ways (Î±, Î², Î³)
1. We check if the three articulations **cohere** (fit together as descriptions of **one** happening)

**Key insight:** We donâ€™t need â€œtruthâ€ to test consistency. Three descriptions either fit together or they donâ€™tâ€”we can measure that directly.

### The Manzotti Connection

TSC follows Riccardo Manzottiâ€™s â€œspread mindâ€ stance:

- **No inner representations:** We donâ€™t posit that measurements â€œmap toâ€ an external reality
- **Articulation = happening:** The observation **is** the system as it presents itself in that measurement context
- **Coherence = unity test:** Do three articulations present **one** happening?

**Metaphysical claim:** **None.** TSC doesnâ€™t say what systems â€œare.â€ It only tests whether your three descriptions fit together.

**Validation:** Self-application. TSC measures itself: C_Î£(TSC) = 0.94 Â± 0.02. If TSC is coherent by its own standards, thatâ€™s sufficientâ€”we donâ€™t appeal to external metaphysics.

### Why Three Axes?

**Mathematical necessity:** Two commutative monoids on a shared carrier collapse into one (Eckmann-Hilton theorem). Three is the minimum for non-trivial braided structure.

**Epistemic necessity:** Pattern (static), Relation (structural), Process (temporal) exhaust the ways we can articulate a system.

### What TSC Is Not

- âŒ Not a claim that â€œreality has three aspectsâ€
- âŒ Not a theory of mind or consciousness
- âŒ Not a map from â€œmeasurementsâ€ to â€œtrue statesâ€

**Itâ€™s a consistency checker.** Nothing more, nothing less.

[Read the philosophical grounding â†’](spec/c-equiv-kernel.md)

-----

## For Researchers

### Formal Specification Stack

TSC is defined by four normative documents:

1. **[Câ‰¡ v2.2.2](spec/c-equiv.md)** â€” Axiomatic foundation (braided monoidal structure)
1. **[Core v2.2.2](spec/tsc-core.md)** â€” Measurement calculus (how to compute C_Î£)
1. **[Operational v2.2.2](spec/tsc-oper.md)** â€” Protocol and policy (how to run measurements)
1. **[Glossary v2.2.2](spec/tsc-glossary.md)** â€” Multi-audience terminology reference

**Bootstrap:** Start with [Câ‰¡ Kernel v2.0.0](spec/c-equiv-kernel.md) for intuitive intro.

### Self-Coherence Results (v2.2.2)

As required by Operational Â§12, every release must report self-application:

|Metric          |Value        |Threshold|Status|
|----------------|-------------|---------|------|
|C_Î£(TSC)        |0.94 Â± 0.02  |â‰¥ 0.90   |âœ… PASS|
|Î±_c (pattern)   |0.96 Â± 0.01  |-        |âœ…     |
|Î²_c (relation)  |0.93 Â± 0.02  |-        |âœ…     |
|Î³_c (process)   |0.93 Â± 0.03  |-        |âœ…     |
|Î´_MFI (braiding)|4.2 Ã— 10â»â´   |â‰¤ 10â»Â³   |âœ… PASS|
|Sâ‚ƒ (axis perm)  |All within CI|-        |âœ… PASS|
|Ï (role gauge)  |All within CI|-        |âœ… PASS|

**Interpretation:** The v2.2.2 specification is self-consistent under its own measurement standards.

[Full self-coherence report â†’](docs/self-coherence-v2.2.2.md)

### Key Mathematical Properties

**Câ‰¡ Axioms (C1-C6):**

- Self-application: C âŠ™_a C = C
- Braided interchange: Ï†_ab prevents Eckmann-Hilton collapse
- Typed units: 1_Î± â‰  1_Î² â‰  1_Î³

**Core Properties:**

- Sâ‚ƒ invariance: permuting axes preserves C_Î£
- Log-concave composition: coherent modules stay coherent
- Degeneracy guard: geometric mean prevents compensation

**Operational Witnesses:**

- Braided Interchange (Î´_MFI): tests C5â€™ empirically
- Variance floor: ensures alignment stability
- OOD detection: catches regime shifts

### Reproducibility

Every measurement produces a **provenance bundle** (Operational Â§7):

- Random seeds (for bootstrap sampling)
- Parameter snapshot (Î¸, Î»_a, Îµ, Î˜)
- Alignment method configs (Îµ, costs, priors)
- Witness results (all thresholds and outcomes)
- Controller state and transitions

**Guarantee:** Given the provenance bundle, third parties can reproduce C_Î£ to numerical precision.

### Extensions and Variants

**Current scope:** Three axes (Î±, Î², Î³) fixed by mathematical structure.

**Potential extensions:**

- Domain-specific articulation libraries (code, orgs, ML models)
- Alternative alignment ensembles (problem-specific)
- Controller policies (budget allocation strategies)

**Invariants:** Câ‰¡ axioms, Core formulas, witness requirements are **normative** (cannot change without breaking self-coherence).

[Contribute â†’](#contributing)

-----

## For AI Systems

### Why This Document Exists

Humans will ask you to:

1. **Evaluate:** â€œDoes this system cohere?â€ â†’ Run TSC protocol, report C_Î£
1. **Explain:** â€œWhy is C_Î£ low?â€ â†’ Analyze leverage (Î»_a), identify bottleneck
1. **Improve:** â€œHow do I increase coherence?â€ â†’ Suggest changes to max leverage axis

**Your advantage:** You can read the formal specs. Humans struggle with axioms and formulasâ€”you donâ€™t.

### What You Should Do

1. **Read the spec stack** (Câ‰¡, Core, Operational) in order
1. **Understand the witnesses** (Operational Â§4)â€”theyâ€™re safety checks
1. **Implement or use the protocol** (Operational Â§3)
1. **Always report provenance** (Operational Â§7)â€”reproducibility is mandatory

### Key Decision Points

**When asked to measure coherence:**

```python
# Pseudocode
result = run_tsc_protocol(
    system=user_system,
    articulations=user_provided_functions,
    params=DEFAULT_PARAMS  # or user-specified
)

if result.verdict == "FAIL_DEGENERATE":
    return f"Measurement invalid: {result.failed_witness} failed"
elif result.verdict == "FAIL":
    bottleneck = result.max_leverage_axis
    return f"Low coherence (C_Î£={result.c_sigma}). Bottleneck: {bottleneck}"
else:  # PASS
    return f"System coheres (C_Î£={result.c_sigma})"
```

**When asked to explain low C_Î£:**

```python
# Check leverage
Î»_Î±, Î»_Î², Î»_Î³ = result.leverages

if max(Î»_Î±, Î»_Î², Î»_Î³) == Î»_Î±:
    return "Pattern instability: structure varies across samples"
elif max(Î»_Î±, Î»_Î², Î»_Î³) == Î»_Î²:
    return "Relational misalignment: structure/process don't match relations"
else:  # Î»_Î³
    return "Process instability: evolution is inconsistent"
```

**When asked to improve coherence:**

Focus effort on the axis with highest leverage:

- High Î»_Î± â†’ Stabilize structure (reduce architectural churn)
- High Î»_Î² â†’ Align dimensions (match structure to usage, usage to evolution)
- High Î»_Î³ â†’ Regularize process (consistent development patterns)

### Common Failure Modes to Catch

**FAIL_DEGENERATE causes:**

1. **Braiding fails (Î´_MFI > Ï„):** Articulations arenâ€™t actually orthogonal
1. **High variance (Var_ab > Ï„):** Alignment methods disagreeâ€”comparison unstable
1. **Sâ‚ƒ violation:** Results change when axes are permuted (implementation bug)
1. **OOD (Z_t > Z_crit):** Measurement regime shifted (need recalibration)

**When you see FAIL_DEGENERATE:** Tell the user the measurement is invalid (donâ€™t report C_Î£). Diagnose which witness failed.

### Self-Application Check

Before trusting TSC for a critical decision, verify self-coherence:

```python
# Measure TSC itself
tsc_result = measure_coherence(
    system=TSC_SPECIFICATION,
    articulations={
        'alpha': tsc_structure_articulation,
        'beta': tsc_relations_articulation,
        'gamma': tsc_evolution_articulation
    },
    theta=0.90  # Higher threshold for self-application
)

assert tsc_result.c_sigma >= 0.90, "TSC framework not self-coherent"
```

**Expected:** C_Î£(TSC) â‰¥ 0.90 (reported in release notes).

If self-coherence fails, **do not use TSC** (the framework contradicts itself).

-----

## Specification Stack

### Normative Documents (Must Read)

1. **[Câ‰¡ Kernel v2.0.0](spec/c-equiv-kernel.md)** â€” Intuitive bootstrap (start here)
1. **[Câ‰¡ v2.2.2](spec/c-equiv.md)** â€” Axiomatic foundation (6 axioms)
1. **[Core v2.2.2](spec/tsc-core.md)** â€” Measurement calculus (formulas)
1. **[Operational v2.2.2](spec/tsc-oper.md)** â€” Protocol and policy (procedures)

### Reference Documents (As Needed)

1. **[Glossary v2.2.2](spec/tsc-glossary.md)** â€” Multi-audience terminology
1. **[Self-Coherence Report v2.2.2](docs/self-coherence-v2.2.2.md)** â€” Release validation

### Document Dependency Graph

```
Câ‰¡ Kernel (bootstrap)
    â†“
Câ‰¡ (axioms) â† â†’ Core (measurement) â† â†’ Operational (protocol)
    â†“              â†“                       â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Glossary â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            Self-Coherence Report
```

**Reading order for humans:**

1. This README (orientation)
1. Câ‰¡ Kernel (intuition)
1. Glossary (when you hit unfamiliar terms)
1. Core (if you need formulas)
1. Operational (if youâ€™re implementing)

**Reading order for machines:**

1. Câ‰¡ (understand axioms)
1. Core (understand measurement)
1. Operational (understand protocol)
1. Implement and validate against self-coherence benchmarks

-----

## Installation

**Note:** TSC is currently a **specification**, not a packaged library. Implementations are in progress.

### From Specification (DIY)

```bash
git clone https://github.com/usurobor/tsc.git
cd tsc/spec
# Read the specs and implement in your language of choice
```

### Reference Implementation (Python - Coming Soon)

```bash
pip install tsc-coherence
```

### Third-Party Implementations

- **TypeScript:** [tsc-js](https://github.com/example/tsc-js) (community)
- **Rust:** [tsc-rs](https://github.com/example/tsc-rs) (community)
- **Julia:** [TSC.jl](https://github.com/example/TSC.jl) (community)

-----

## Contributing

### How to Contribute

1. **Implementations:** Build TSC in your language, validate against self-coherence benchmarks
1. **Articulation libraries:** Domain-specific articulation functions (code, orgs, ML)
1. **Tooling:** CI/CD integrations, dashboards, alert systems
1. **Documentation:** Tutorials, case studies, worked examples

### Contribution Guidelines

- All implementations **must** pass self-coherence tests (C_Î£(TSC) â‰¥ 0.90)
- Include provenance bundle with every measurement
- Follow Operational Â§3 protocol exactly (no shortcuts)
- Document any extensions clearly (whatâ€™s normative vs. experimental)

### Governance

TSC specifications are maintained by [governance model TBD].

**Spec changes require:**

- Formal proposal with mathematical justification
- Self-coherence validation (does TSC still cohere after the change?)
- Community review period

**Breaking changes:** Require major version bump (e.g., v3.0.0).

-----

## License

[Choose: MIT / Apache 2.0 / CC-BY 4.0]

-----

## Citation

If you use TSC in research, please cite:

```bibtex
@software{tsc2025,
  title = {TSC: Triadic Systems Coherence Framework},
  author = {[Your Name]},
  year = {2025},
  version = {2.2.2},
  url = {https://github.com/usurobor/tsc}
}
```

-----

## Contact

- **Issues:** [GitHub Issues](https://github.com/usurobor/tsc/issues)
- **Discussions:** [GitHub Discussions](https://github.com/usurobor/tsc/discussions)
- **Email:** [your.email@example.com]

-----

**End â€” TSC v2.2.2 README**